{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cedba70d",
   "metadata": {},
   "source": [
    "## Описание проекта\n",
    "Интернет-магазин запускает новый сервис, чтобы пользователи могли редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba557e70",
   "metadata": {},
   "source": [
    "## Загружу и подготовлю данные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e8247",
   "metadata": {},
   "source": [
    "Установлю отсутствующие в окружении библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c170700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53cabfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d567fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f5643",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674faa9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba1326e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переустановка и апгрейд numpy, если есть проблемы с использованием Gensim\n",
    "#!pip uninstall numpy\n",
    "#!pip install numpy\n",
    "#!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87952e53",
   "metadata": {},
   "source": [
    "Импортирую библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb04f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9849c10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec66488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для эмбендингов\n",
    "import tensorflow\n",
    "from transformers import TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41fd506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "# для лемматизации через WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download() # загрузка пакетов через всплывающее окно\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d40504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a76cd5b",
   "metadata": {},
   "source": [
    "### Изучу общую информацио о данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf51c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6cda067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7313bb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "903258d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839639a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade353e",
   "metadata": {},
   "source": [
    "Данные полные, соотношение классов нормальное. Для дальнейшей работы с ними, требуется предобработка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9689e43",
   "metadata": {},
   "source": [
    "### Проведу лемматизацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c5bb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804cc02",
   "metadata": {},
   "source": [
    "#### Напишу свои функции для лемматизации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa37d85",
   "metadata": {},
   "source": [
    "Сохраню 5 строк для тестирования, чтобы не ждать долго:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fbf0804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp = df.head().copy()\n",
    "df_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ad31938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    m = Mystem()\n",
    "    lemm_list = m.lemmatize(text)\n",
    "    lemm_text = \"\".join(lemm_list)\n",
    "    return lemm_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732cb413",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note: </b> Оказывается, этот лемматизатор работает только с русским языком, так что его нет смысла применять.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3108aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text): # функция для очистки текста\n",
    "    return \" \".join(re.sub(r'[^a-zA-Z]', ' ', text).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0285b4f",
   "metadata": {},
   "source": [
    "Проверю работу функций на первом элементе корпуса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ae1b34c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "Очищенный и лемматизированный текст в нижнем регистре: explanation why the edits made under my username hardcore metallica fan were reverted they weren t vandalisms just closure on some gas after i voted at new york dolls fac and please don t remove the template from the talk page since i m retired now\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Исходный текст:\", corpus[0])\n",
    "print(\"Очищенный и лемматизированный текст в нижнем регистре:\", lemmatize(clear_text(corpus[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4140308",
   "metadata": {},
   "source": [
    "Уже на 1 предложении видно, что лемматизация происходит медленно. Попробую циклом пройтись по первым 5 элементами корпуса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3aa0f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.46 ms, sys: 32.2 ms, total: 39.6 ms\n",
      "Wall time: 23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['explanation why the edits made under my username hardcore metallica fan were reverted they weren t vandalisms just closure on some gas after i voted at new york dolls fac and please don t remove the template from the talk page since i m retired now\\n',\n",
       " 'd aww he matches this background colour i m seemingly stuck with thanks talk january utc\\n',\n",
       " 'hey man i m really not trying to edit war it s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info\\n',\n",
       " 'more i can t make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay until a reviewer turns up it s listed in the relevant form eg wikipedia good article nominations transport\\n',\n",
       " 'you sir are my hero any chance you remember what page that s on\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lemm_text_list = []\n",
    "for i in list(df_exp['text'].head()):\n",
    "    lemm_text_list.append(lemmatize(clear_text(i)))\n",
    "lemm_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dad2d2",
   "metadata": {},
   "source": [
    "Другой метод пройти по столбцу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c00ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_exp = df_exp['text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4656a150",
   "metadata": {},
   "source": [
    "Лемматизирую, но прежде очищу с помощью созданной ранее фукции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe949455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.09 ms, sys: 30.9 ms, total: 39 ms\n",
      "Wall time: 7.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_exp['lemm_text'] = [lemmatize(clear_text(i)) for i in corpus_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1ca46ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he matches this background colour i m se...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestions on impr...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a50f9",
   "metadata": {},
   "source": [
    "Лемматизация через цикл работает очень медленно, не буду использовать этот метод.  \n",
    "Думаю, стоит использовать модели с встроенной лемматизацией и токенизацией или иной метод лемматизации, чтобы попробовать Логистическую регрессию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80b666",
   "metadata": {},
   "source": [
    "#### Попробую лемматизацию WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9c62e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')\n",
    "snowball_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5fa902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_exp = df_exp['text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0849ed4e",
   "metadata": {},
   "source": [
    "Инициализирую Wordnet Lemmatizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d3ccdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71f15402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests\n"
     ]
    }
   ],
   "source": [
    "# проверяю работу Wordnet Lemmatizer на примере:\n",
    "print(lemmatizer.lemmatize(\"Tests\").lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bd1880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    return \" \".join(re.sub(r'[^a-zA-Z]', ' ', text).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "515aa0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_text(text):\n",
    "    #lowerized = lemmatizer.lemmatize(text) # лемматизирую\n",
    "    word_tokens = nltk.word_tokenize(text) # разбиваю текст на токены-слова\n",
    "    removing_stopwords = [word for word in word_tokens if word not in stopword] # удаляю стоп-слова\n",
    "    wordnet_lemmatizer = WordNetLemmatizer() \n",
    "    lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in removing_stopwords] # лемматизирую\n",
    "    return clear_text(text).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ea0edaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 9s, sys: 1.37 s, total: 3min 10s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['lemm_text'] = df['text'].apply(lemm_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72c5a8",
   "metadata": {},
   "source": [
    "Лемматизация работает."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e59159",
   "metadata": {},
   "source": [
    "### Разобью датасет на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e604ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127656, 3), (31915, 3))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2,  random_state=12345)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3728c93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95742, 3), (31914, 3))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid = train_test_split(\n",
    "    train, test_size=0.25,  random_state=12345)\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b7745",
   "metadata": {},
   "source": [
    "## Обучу разные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7424d7a8",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93dfc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(verbose=100,\n",
    "                           iterations=1500,\n",
    "                           learning_rate=0.7,\n",
    "                           early_stopping_rounds=200,\n",
    "                           eval_metric='F1',\n",
    "                           auto_class_weights='Balanced',\n",
    "                           random_seed=12345,\n",
    "                           use_best_model=True,\n",
    "                           depth=8\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "596b314b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8122141\ttest: 0.8370509\tbest: 0.8370509 (0)\ttotal: 1.19s\tremaining: 29m 39s\n",
      "100:\tlearn: 0.9227164\ttest: 0.8648860\tbest: 0.8744499 (20)\ttotal: 57.9s\tremaining: 13m 22s\n",
      "200:\tlearn: 0.9533163\ttest: 0.8533223\tbest: 0.8744499 (20)\ttotal: 1m 55s\tremaining: 12m 24s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.874449926\n",
      "bestIteration = 20\n",
      "\n",
      "Shrink model to first 21 iterations.\n",
      "CPU times: user 6min 8s, sys: 57 s, total: 7min 5s\n",
      "Wall time: 2min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x24d011e10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train[['text']], train[['toxic']],\n",
    "          eval_set=(valid[['text']], valid[['toxic']]),\n",
    "          text_features=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebabceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.94     28676\n",
      "           1       0.47      0.84      0.61      3239\n",
      "\n",
      "    accuracy                           0.89     31915\n",
      "   macro avg       0.73      0.87      0.77     31915\n",
      "weighted avg       0.93      0.89      0.90     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_catboost = model.predict(test[['text']])\n",
    "print(classification_report(test['toxic'], pred_catboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cab853e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6063971568191916"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test['toxic'], pred_catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d9266c",
   "metadata": {},
   "source": [
    "Маленькое значение метрики ;("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff8cf3",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f771c44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/elizaveta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee6f19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9983ade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.94 s, sys: 2.03 s, total: 9.97 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus_train = train['lemm_text'].values.astype('U')\n",
    "tfidf_train = tfidf.fit_transform(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f581205a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizaveta/opt/anaconda3/envs/praktikum/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=200, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12345, solver='warn', tol=0.0001, verbose=50,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', max_iter=200, random_state=12345, verbose=50)\n",
    "model.fit(tfidf_train, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c954458",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_valid = valid['lemm_text'].values.astype('U')\n",
    "tfidf_valid = tfidf.transform(corpus_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "006578e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(tfidf_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cc38866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 для Линейной регрессии: 0.7527863569222506\n"
     ]
    }
   ],
   "source": [
    "print('Метрика F1 для Линейной регрессии:', f1_score(valid['toxic'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33244621",
   "metadata": {},
   "source": [
    "На Линейной регрессии получил приемлемую метрику F1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78445a4d",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75059355",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(\n",
    "        loss='hinge', # в кач-ве функции потерь использую Support Vector Machine\n",
    "        penalty='l2',\n",
    "        alpha=1e-3,\n",
    "        random_state=12345,\n",
    "        max_iter=5,\n",
    "        tol=None,\n",
    "        verbose=10)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c32d61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aafe5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(sgdc_clf, parameters, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d562cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizaveta/opt/anaconda3/envs/praktikum/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 5.75, NNZs: 38262, Bias: -0.996527, T: 95742, Avg. loss: 0.167703\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.73, NNZs: 41808, Bias: -0.994547, T: 191484, Avg. loss: 0.165991\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.71, NNZs: 42674, Bias: -0.994177, T: 287226, Avg. loss: 0.165699\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5.71, NNZs: 43070, Bias: -0.993695, T: 382968, Avg. loss: 0.165656\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5.70, NNZs: 43257, Bias: -0.993464, T: 478710, Avg. loss: 0.165566\n",
      "Total training time: 0.33 seconds.\n",
      "CPU times: user 9.22 s, sys: 2.05 s, total: 11.3 s\n",
      "Wall time: 2min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=Non...\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=12345,\n",
       "                                                      shuffle=True, tol=None,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=10,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'clf__alpha': (0.01, 0.001),\n",
       "                         'tfidf__use_idf': (True, False),\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs_clf.fit(train['lemm_text'], train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7355a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gs_clf.predict(valid['lemm_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89323814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7ca950c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 для SGDClassifier: 0.23363491218733373\n"
     ]
    }
   ],
   "source": [
    "print('Метрика F1 для SGDClassifier:', f1_score(valid['toxic'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e1647",
   "metadata": {},
   "source": [
    "Метрика очень плохая, GridSearch не нашёл подходящий параметр или что-то нет так в подготовке данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547bf017",
   "metadata": {},
   "source": [
    "## Сделаю выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10286855",
   "metadata": {},
   "source": [
    "Попробовал разные модели:\n",
    "- CatBoost: получил низкое значение метрики F1 (0.627).\n",
    "- LogisticRegression: если использовать быструю лемматизацию (WordNetLemmatizer), то модель работает довольно быстро и выдаёт хорошую метрику F1 (0.752).\n",
    "- SGDClassifier с GridSearch: из-за перебора модель работает долго и на выходе показывает неприлично слабую метрику F1 (0.224). Тут нужно экспериментировать с параметрами или что-то исправить во входных данных для обучения, модель должна быть на уровне с логистической регрессией.  \n",
    "\n",
    "Самой эффектиной в моей работе оказалась Линейная регрессия с качественной предподготовкой данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
